# To deploy the thing we need to:

# Build the container and push to the repo
docker build --no-cache -t jmccoydev/tasky:latest .
docker push jmccoydev/tasky:latest

# Set the environment becase we are a complete and utter hack.  It's awful but quick.
cd ~/terraform ; terraform init ; export DB_PRIVATE_IP=`terraform output -raw db_private_ip` ; export DB_PUBLIC_IP=`terraform output -raw db_public_ip` ; export CLUSTER_NAME=`terraform output -raw cluster_name`

# Set the kubernetes context
aws eks --region us-east-2 update-kubeconfig --name $CLUSTER_NAME
echo "~~~~~~~~"
echo "you are now talking to EKS cluser "$CLUSTER_NAME
 
# Set the db connect string in the yaml
cd ~/Github/tasky
sed -i "s/\(mongodb:\/\/admin:adminPassword@\)[^:]*\(:27017\/\"\)/\1$DB_PRIVATE_IP\2/" tasky-deployment.yaml
echo "~~~~~~~~"
echo "mongodb connect string updated with internal IP address "$DB_PRIVATE_IP
echo "~~~~~~~~"
echo "Public IP address of the MongoDB server "$DB_PUBLIC_IP
echo "~~~~~~~~"
# Deploy the thing and it's load balancer
echo "Deploy the thing and it's load balancer and cluster role binding"
kubectl apply -f tasky-deployment.yaml
sleep 5
echo "~~~~~~~~"
echo "Checking to see if pods are running..."
kubectl get pods
export POD=`kubectl get pods | grep tasky -m 1 | awk '{print $1}'` 
echo "~~~~~~~~"
echo "Check the service for the ingress point..."
kubectl get services | grep Load
echo "~~~~~~~~"
echo "This is the required cluster admin role binding"
kubectl describe clusterrolebinding wiz-cluster-admin-binding
echo "~~~~~~~~"
echo "Service account name for the cluster-admin role binding"
kubectl get serviceaccounts
echo "~~~~~~~~"
echo "Wizexercise.txt file from the running container"
echo "~~~~~~~~"
kubectl exec $POD -c tasky -- cat /tmp/wizexercise.txt
echo "~~~~~~~~"
